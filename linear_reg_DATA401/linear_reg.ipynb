{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 401 Project 1\n",
    "Team Rum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and setup training sets\n",
    "\n",
    "df = pd.read_csv(\"data/aggdata08.csv\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# shuffle\n",
    "df = df.sample(frac=1)\n",
    "X = df.drop(['volume_sold_l', 'volume_per_cap'], axis=1)\n",
    "X['intercept'] = 1\n",
    "Y = df['volume_per_cap'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(data, y, features):\n",
    "    \"\"\"\n",
    "    Generate linear regression model coefficients\n",
    "    \n",
    "    Params:\n",
    "        data -- a pandas dataframe containing data (assumed to contain intercept \n",
    "                                                    column and no response variable)\n",
    "        y -- a pandas series containing response variable\n",
    "        features -- a list of strings containing which features to include in model\n",
    "                    (do not include 'intercept', it will be automatically added)\n",
    "                    \n",
    "    Returns:\n",
    "        A numpy array containing model coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    features = [\"intercept\"] + features\n",
    "    mat_data = data.as_matrix(features)\n",
    "    betas = (np.matmul(np.matmul(np.linalg.inv(np.matmul(mat_data.T, mat_data)), mat_data.T), y.as_matrix()))\n",
    "    return betas\n",
    "\n",
    "\n",
    "def calc_bic(data, y, coef, features):\n",
    "    \"\"\"\n",
    "    Calculate BIC metric for a model\n",
    "    \n",
    "    Params:\n",
    "        data -- a pandas dataframe containing data (assumed to contain intercept \n",
    "                                                    column and no response variable)\n",
    "        y -- a pandas series containing response variable\n",
    "        coef -- numpy array containing model coefficients\n",
    "        features -- a list of strings containing which features to include in model\n",
    "                    (do not include 'intercept', it will be automatically added)\n",
    "        \n",
    "    Returns:\n",
    "        A float representing BIC metric\n",
    "    \"\"\"\n",
    "    \n",
    "    features = [\"intercept\"] + features\n",
    "    mat_dat = data.as_matrix(features)\n",
    "    \n",
    "    n = len(data)\n",
    "    var1 = np.matmul(mat_dat, coef.T)    \n",
    "    residuals = y.as_matrix() - var1\n",
    "    sse = np.sum(residuals**2)\n",
    "    sst = y.var() * len(y)\n",
    "    #print(\"R^2 = \" + str(1 - sse/sst))\n",
    "\n",
    "    return sse/y.var() + (len(features)-1) * np.log(n)\n",
    "    \n",
    "    \n",
    "def calc_accuracy(X_test, y, coef, features):\n",
    "    \"\"\"\n",
    "    Calculate accuracy metric for a model\n",
    "    \n",
    "    Params:\n",
    "        X_test -- a pandas dataframe containing data (assumed to contain intercept \n",
    "                                                      column and no response variable)\n",
    "        y -- a pandas series containing response variable\n",
    "        coef -- numpy array containing model coefficients\n",
    "        features -- a list of strings containing which features to include in model\n",
    "                    (do not include 'intercept', it will be automatically added)\n",
    "        \n",
    "    Returns:\n",
    "        A float representing accuracy metric\n",
    "    \"\"\"\n",
    "    \n",
    "    features = [\"intercept\"] + features\n",
    "    mat_dat = X_test.as_matrix(features)\n",
    "    \n",
    "    n = len(X_test)\n",
    "    var1 = np.matmul(mat_dat, coef.T)\n",
    "    residuals = y.as_matrix() - var1\n",
    "    sst = y.var() * len(y)\n",
    "    sse = np.sum(residuals**2) \n",
    "    #print(\"R^2 = \" + str(1 - sse/sst))\n",
    "    \n",
    "    return sse/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:43: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chose: avg_vendor_size (10014.204262971787)\n",
      "Chose: num_weeks (8912.813986011446)\n",
      "Chose: average_HH_size (8065.799680824065)\n",
      "Chose: rum_bottles (7663.526096743773)\n",
      "Chose: population (7118.6012233350075)\n",
      "Chose: male_over_21_prop (6805.55116395802)\n",
      "Chose: avg_bottle_price (6557.636221740147)\n",
      "Found Optimal Model, (7 features of 30)\n",
      "['avg_vendor_size', 'num_weeks', 'average_HH_size', 'rum_bottles', 'population', 'male_over_21_prop', 'avg_bottle_price']\n",
      "[ 1.27359756e+00  3.00627782e-04  2.57810772e-04 -3.03295757e-01\n",
      "  3.95469173e-05 -1.56882787e-06 -1.47616723e+00  6.60753284e-03]\n"
     ]
    }
   ],
   "source": [
    "# Forward Stepwise for BIC minimization\n",
    "features = list(X.columns[3:-1])\n",
    "features = list(set(features) - set(['county_bin_quartile1','county_bin_quartile2','county_bin_quartile3','county_bin_quartile4','Seasons_Winter','Seasons_Summer','Seasons_Spring']))\n",
    "\n",
    "last_bic = sys.maxsize    # Last model prediction accuracy\n",
    "model_bic = sys.maxsize   # Current model prediction accuracy\n",
    "interp_features = []     # Current features in model\n",
    "target_feature = None     # Current best feature\n",
    "best_coefs = None\n",
    "\n",
    "while len(interp_features) < len(features):\n",
    "    for feature in list(set(features) - set(interp_features)):\n",
    "        \n",
    "        # Generate model\n",
    "        try_features = interp_features + [feature]\n",
    "        coefs = generate_model(X, Y, try_features)\n",
    "        \n",
    "        # Calculate bic\n",
    "        cur_bic = calc_bic(X, Y, coefs, try_features)\n",
    "        \n",
    "        # Save feature if bic lower than current\n",
    "        if last_bic is None or cur_bic < last_bic:\n",
    "            last_bic = cur_bic\n",
    "            target_feature = feature\n",
    "            \n",
    "    # If the best feature improves the model, add it\n",
    "    if last_bic < model_bic and abs(last_bic-model_bic) > 0.03*model_bic:\n",
    "        interp_features.append(target_feature)\n",
    "        model_bic = last_bic\n",
    "        best_coefs = coefs\n",
    "        print(\"Chose: \" + target_feature + \" (\" + str(model_bic) + \")\")\n",
    "        \n",
    "    # Otherwise we are done\n",
    "    else:\n",
    "        print(\"Found Optimal Model, (%d features of %d)\" % (len(interp_features), len(features)))\n",
    "        print(interp_features)\n",
    "        print(best_coefs)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:68: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/Users/markelle/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:72: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chose: avg_vendor_size (0.006892242137740964)\n",
      "Chose: county_bin_quartile1 (0.006111216947842122)\n",
      "Chose: county_bin_quartile2 (0.0054515465801426525)\n",
      "Chose: county_bin_quartile3 (0.004869743207904271)\n",
      "Chose: county_bin_quartile4 (0.0034987967840558005)\n",
      "Chose: num_weeks (0.0031504603638142655)\n",
      "Chose: head_of_household_prop (0.003058032602564909)\n",
      "Chose: whiskey_bottles (0.0029341722726642034)\n",
      "Chose: owned_housing (0.002596018392948796)\n",
      "Chose: rum_bottles (0.0025037528890311522)\n",
      "Chose: avg_bottle_price (0.002449544499803463)\n",
      "Chose: average_HH_size (0.002427725841642008)\n",
      "Chose: male_over_21_prop (0.002396357104232363)\n",
      "Chose: isHoliday (0.002379070370224324)\n",
      "Chose: pop_density (0.0023627961293756425)\n",
      "Chose: white_prop (0.002344889108856533)\n",
      "Chose: Seasons_Winter (0.002329876285848513)\n",
      "Chose: over_65_prop (0.002315063084833253)\n",
      "Chose: other_bottles (0.002303631924843917)\n",
      "Chose: female_median_age (0.002298017437517505)\n",
      "Chose: median_age (0.0022853449495383164)\n",
      "Chose: tequila_bottles (0.002279542714327575)\n",
      "Chose: 25_to_29_prop (0.002274119723811921)\n",
      "Chose: Seasons_Spring (0.0022705607442214054)\n",
      "Chose: pop_over_21_prop (0.002268381235661258)\n",
      "Chose: gin_bottles (0.002267445031979838)\n",
      "Chose: has_child_prop (0.002266503380230198)\n",
      "Chose: 15_to_19_prop (0.0022663558095009024)\n",
      "Chose: male_median_age (0.002266278486724927)\n",
      "Chose: population (0.002266203452402293)\n",
      "Chose: rented_housing (0.0022553510390649874)\n",
      "Chose: under_5_prop (0.002254402734876395)\n",
      "Chose: 20_to_24_prop (0.0022541608906629313)\n",
      "Chose: num_alc_accidents (0.0022541563263459062)\n",
      "Found Optimal Model, (34 features of 37)\n",
      "['avg_vendor_size', 'county_bin_quartile1', 'county_bin_quartile2', 'county_bin_quartile3', 'county_bin_quartile4', 'num_weeks', 'head_of_household_prop', 'whiskey_bottles', 'owned_housing', 'rum_bottles', 'avg_bottle_price', 'average_HH_size', 'male_over_21_prop', 'isHoliday', 'pop_density', 'white_prop', 'Seasons_Winter', 'over_65_prop', 'other_bottles', 'female_median_age', 'median_age', 'tequila_bottles', '25_to_29_prop', 'Seasons_Spring', 'pop_over_21_prop', 'gin_bottles', 'has_child_prop', '15_to_19_prop', 'male_median_age', 'population', 'rented_housing', 'under_5_prop', '20_to_24_prop', 'num_alc_accidents']\n",
      "[ 1.50259609e+00  1.76924320e-04 -4.39474918e-01 -3.95866267e-01\n",
      " -3.67081679e-01 -3.34202673e-01  1.60315286e-04  1.38218291e+00\n",
      "  7.87916952e-06 -1.40114327e-05  1.97312221e-05 -1.14109059e-02\n",
      " -1.91898038e-01 -1.33417132e+00  8.87051479e-03 -6.55754169e+02\n",
      " -2.28124671e-01 -1.06775447e-02 -7.01960928e-01  3.86775267e-06\n",
      "  1.62815558e-02 -1.19252644e-02 -9.29402807e-06  9.67385066e-01\n",
      " -4.23196825e-03 -6.53568250e-01  2.80703796e-06 -2.00645670e-01\n",
      " -1.15414091e-01  5.14513947e-03  1.20624875e-05 -1.28169156e-05\n",
      "  4.45853802e-01 -1.15228744e-01 -4.00301936e-04]\n"
     ]
    }
   ],
   "source": [
    "# Forward Stepwise for prediction error minimization\n",
    "features = list(X.columns[3:-1])\n",
    "\n",
    "last_err = sys.maxsize    # Last model prediction accuracy\n",
    "model_err = sys.maxsize   # Current model prediction accuracy\n",
    "pred_features = []     # Current features in model\n",
    "target_feature = None     # Current best feature\n",
    "best_coefs = None\n",
    "\n",
    "while len(pred_features) < len(features):\n",
    "    for feature in list(set(features) - set(pred_features)):\n",
    "        \n",
    "        # Cross validate\n",
    "        folds = 5\n",
    "        sp = len(X)/folds\n",
    "        err = []\n",
    "        for i in range(folds):\n",
    "            lower = int(sp * i)\n",
    "            upper = int(sp * (i+1))\n",
    "            test_x = X.iloc[lower:upper]\n",
    "            test_y = Y.iloc[lower:upper]\n",
    "            train_x = pd.concat((X.iloc[:lower], X.iloc[upper:]))\n",
    "            train_y = pd.concat((Y.iloc[:lower], Y.iloc[upper:]))\n",
    "            \n",
    "            # Generate model\n",
    "            try_features = pred_features + [feature]\n",
    "            coefs = generate_model(train_x, train_y, try_features)\n",
    "        \n",
    "            # Calculate predction error\n",
    "            err += [calc_accuracy(test_x, test_y, coefs, try_features)]\n",
    "            \n",
    "        cur_err = sum(err)/len(err)\n",
    "        \n",
    "        # Save feature if error lower than current\n",
    "        if last_err is None or cur_err < last_err:\n",
    "            last_err = cur_err\n",
    "            target_feature = feature\n",
    "            best_coefs = coefs\n",
    "    \n",
    "    # If the best feature improves the model, add it\n",
    "    if last_err < model_err:\n",
    "        pred_features.append(target_feature)\n",
    "        model_err = last_err\n",
    "        print(\"Chose: \" + target_feature + \" (\" + str(model_err) + \")\")\n",
    "        \n",
    "    # Otherwise we are done\n",
    "    else:\n",
    "        print(\"Found Optimal Model, (%d features of %d)\" % (len(pred_features), len(features)))\n",
    "        print(pred_features)\n",
    "        print(best_coefs)\n",
    "        calc_accuracy(test_x, test_y, best_coefs, pred_features)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
