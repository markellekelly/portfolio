{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "macro = pd.read_csv(\"macro.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Merge train and macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine on timestamp, keeping all observations from train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = train.merge(macro, on=\"timestamp\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate columns with fewer missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nas = comb.isnull().sum(axis = 0)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    pass\n",
    "    #print(train_nas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset dataframe to only our chosen 39 explanatory variables and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = comb[[\"full_sq\", \"life_sq\", \"floor\", \"num_room\", \"state\", \"product_type\", \n",
    "          \"raion_popul\", \"green_zone_part\",\"indust_part\", \"children_preschool\",\n",
    "           \"children_school\", \"healthcare_centers_raion\", \"university_top_20_raion\",\n",
    "         \"culture_objects_top_25_raion\", \"shopping_centers_raion\", \"oil_chemistry_raion\",\n",
    "         \"radiation_raion\", \"railroad_terminal_raion\", \"big_market_raion\", \n",
    "           \"nuclear_reactor_raion\",\"detention_facility_raion\", \"work_all\", \"ekder_all\",\n",
    "         \"park_km\", \"public_transport_station_km\", \"big_road1_km\", \"fitness_km\", \n",
    "          \"big_church_count_5000\", \"mosque_count_5000\", \"cafe_avg_price_5000\", \n",
    "         \"office_count_5000\", \"ecology\",'salary','cpi','usdrub','mortgage_rate',\n",
    "          'unemployment','bandwidth_sports','rent_price_2room_eco',\"price_doc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Cleaning & dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### life_sq, full_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 435 observations with 0 or 1 living square meters\n",
      "- 21 of these have full square meters of 0 or 1\n",
      "\n",
      "- 37 observations with life_sq > full_sq\n",
      "- these have life_sq mean = 348.86486486486484, std = 1215.8504376718324, range [38.0,7478.0]\n",
      "- full_sq mean = 44.45945945945946, std = 26.494857566657675, range [0,84]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ls2 = len(df[df['life_sq']<2])\n",
    "ls2fs = len(df[np.logical_and(df['life_sq']<2,df['full_sq']<2)])\n",
    "comp_fs = len(df[df['life_sq']>df['full_sq']])\n",
    "comp_fsm = df[df['life_sq']>df['full_sq']]['life_sq'].mean()\n",
    "comp_fsm2 = df[df['life_sq']>df['full_sq']]['full_sq'].mean()\n",
    "comp_fsm_s = df[df['life_sq']>df['full_sq']]['life_sq'].std()\n",
    "comp_fsm2_s = df[df['life_sq']>df['full_sq']]['full_sq'].std()\n",
    "min1 = df[df['life_sq']>df['full_sq']]['life_sq'].min()\n",
    "max1 = df[df['life_sq']>df['full_sq']]['life_sq'].max()\n",
    "min2 = df[df['life_sq']>df['full_sq']]['full_sq'].min()\n",
    "max2 = df[df['life_sq']>df['full_sq']]['full_sq'].max()\n",
    "\n",
    "print(\"- \" + str(ls2) + \" observations with 0 or 1 living square meters\")\n",
    "print(\"- \" + str(ls2fs) + \" of these have full square meters of 0 or 1\\n\")\n",
    "print(\"- \" + str(comp_fs) + \" observations with life_sq > full_sq\")\n",
    "print(\"- \" + \"these have life_sq mean = \"+ str(comp_fsm) + \", std = \" + str(comp_fsm_s) +\n",
    "     \", range [\" + str(min1) + \",\" + str(max1) + \"]\")\n",
    "print(\"- \" + \"full_sq mean = \"+ str(comp_fsm2) + \", std = \" + str(comp_fsm2_s) +\n",
    "     \", range [\" + str(min2) + \",\" + str(max2) + \"]\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 435 observations with 0 or 1 living square meters, only 21 of which have similarly small full square meters. Since these data are on sales of houses, it's probably safe to assume that a value of <= 1 square meters of living space is a mistake.\n",
    "For the 414 observations with a reasonable full_sq value but 0 or 1 for life_sq, we set life_sq to NaN to later fill in with a more helpful estimate of life_sq.\n",
    "\n",
    "There are also 37 observations where living square meters is greater than the full square meters. Each of these has a full_sq value of less than 100 meters, while life_sq values average around 350. For these, we set life_sq to NaN to later fill in with a more helpful estimate.\n",
    "\n",
    "Then, double check that we don't have any rows with NaN for both full_sq and life_sq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[np.logical_and(df['life_sq']<2,df['full_sq']>20), \"life_sq\"] = np.nan\n",
    "df.loc[np.logical_and(df['life_sq']>10,df['full_sq']<2), \"full_sq\"] = np.nan\n",
    "df.loc[np.logical_and(df['life_sq']>df['full_sq'],df['full_sq']<10), \"full_sq\"] = np.nan\n",
    "df.loc[df['life_sq']>df['full_sq'],\"life_sq\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df[np.logical_or(df['life_sq']<2,df['full_sq']<2)]) == 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df[np.logical_and(df['life_sq'].isnull(),df['full_sq'].isnull())]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get average proportion of life_sq / full_sq to help fill in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445236350818558 0.1663612277314424 0.4423223378652508\n"
     ]
    }
   ],
   "source": [
    "mean = (df[\"life_sq\"]/df[\"full_sq\"]).mean()\n",
    "std = (df[\"life_sq\"]/df[\"full_sq\"]).std()\n",
    "corr = df['life_sq'].corr(df['full_sq'])\n",
    "print(mean, std, corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill null values of life_sq with average proportion * full_sq and fill null values of full_sq with life_sq / average proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['life_sq'] = df[\"life_sq\"].fillna(df[\"full_sq\"]*mean)\n",
    "df['full_sq'] = df[\"full_sq\"].fillna(df[\"life_sq\"]/mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[np.logical_or(df['life_sq']<2,df['full_sq']<2),[\"life_sq\",\"full_sq\"]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['life_sq'] = df[\"life_sq\"].fillna(df[\"life_sq\"].mean())\n",
    "df['full_sq'] = df[\"full_sq\"].fillna(df[\"full_sq\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### floor, cafe_avg_price_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "297\n"
     ]
    }
   ],
   "source": [
    "print(df[\"floor\"].isna().sum())\n",
    "print(df[\"cafe_avg_price_5000\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are less than 300 missing values (less than 1% of observations) for number of floors and average cafe price, we chose to simply fill in NaNs with the average of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"floor\"] = df[\"floor\"].fillna(df[\"floor\"].mean())\n",
    "df[\"cafe_avg_price_5000\"] = df[\"cafe_avg_price_5000\"].fillna(\n",
    "    df[\"cafe_avg_price_5000\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### product_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map product type to a binary variable, where 1 means the property was an investment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_type'] = df['product_type'].map({'Investment':1, 'OwnerOccupier':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_room'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more missing values for num_room - almost 1/3 of the dataset - so it is preferable to avoid using a simple mean to fill in. Since num_room is very likely related to size of living space, we choose to forward-fill in null values for num_room, sorting by life_sq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"life_sq\")\n",
    "df['num_room'] = df['num_room'].fillna(method='ffill')\n",
    "df = df.sort_values(by=\"life_sq\",ascending=False)\n",
    "df['num_room'] = df['num_room'].fillna(method='ffill')\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13559 missing values\n",
      "values included: [nan  3.  1.  2.  4. 33.]\n",
      "1 observations with state=33\n"
     ]
    }
   ],
   "source": [
    "print(str(df['state'].isnull().sum()) + \" missing values\")\n",
    "print(\"values included: \" + str(df['state'].unique()))\n",
    "print(str(len(df[df['state']==33])) + \" observations with state=33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State seems to be on a scale of 1-4. There is one value of 33, which seems to be a mistake, so we will set this to NaN. There are lots of missing values for state - a little under 1/2 of the dataset. Because of this, it would likely hurt us to try to estimate these values. However, the condition of the house is a very helpful feature for the houses that do have it recorded. In order to keep this helpful information and not dilute it with estimated values, we designate a value of 0 to represent an unknown state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['state']==33,\"state\"] = np.nan\n",
    "df['state'] = df['state'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ecology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'excellent', 'poor', 'satisfactory', 'no data'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ecology'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert ecology (ordinal) to numeric. Use 0 for 'no data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ecology'] = df['ecology'].map({'poor':1, 'satisfactory':2,'good':3,'excellent':4,'no data':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oil_chemistry_raion, radiation_raion, railroad_terminal_raion, big_market_raion, nuclear_reactor_raion, detention_facility_raion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map values from no/yes to 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fix = [\"oil_chemistry_raion\", \"radiation_raion\", \"railroad_terminal_raion\",\n",
    "          \"big_market_raion\", \"nuclear_reactor_raion\", \"detention_facility_raion\"]\n",
    "for col in to_fix:\n",
    "    df[col] = df[col].map({'yes':1, 'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final check & export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure columns have no missing values and are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    assert df[col].isnull().sum() == 0\n",
    "    assert df[col].dtype == np.float64 or df[col].dtype == np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\",encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
